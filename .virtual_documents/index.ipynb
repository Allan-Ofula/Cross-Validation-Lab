





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
get_ipython().run_line_magic("matplotlib", " inline")

ames = pd.read_csv('ames.csv')

continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']
categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']

ames_cont = ames[continuous]

# log features
log_names = [f'{column}_log' for column in ames_cont.columns]

ames_log = np.log(ames_cont)
ames_log.columns = log_names

# normalize (subract mean and divide by std)

def normalize(feature):
    return (feature - feature.mean()) / feature.std()

ames_log_norm = ames_log.apply(normalize)

# one hot encode categoricals
ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)

preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)

X = preprocessed.drop('SalePrice_log', axis=1)
y = preprocessed['SalePrice_log']





# Import train_test_split from sklearn.model_selection

from sklearn.model_selection import train_test_split


# Split the data into training and test sets (assign 20% to test set)

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)





# Import LinearRegression from sklearn.linear_model

from sklearn.linear_model import LinearRegression


# Instantiate and fit a linear regression model

# Instantiate and fitting
model = LinearRegression()
model.fit(X_train, y_train)





# Import mean_squared_error from sklearn.metrics

from sklearn.metrics import mean_squared_error


# Calculate MSE on test set

# Prediction on test set
y_pred = model.predict(X_test)

# Calculating MSE
mse = mean_squared_error(y_test, y_pred)

print(f"Test MSE: {mse}")





# Import cross_val_score from sklearn.model_selection

from sklearn.model_selection import cross_val_score


# Find MSE scores for a 5-fold cross-validation

# 5-fold cross-validation
mse_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')

# Since scores are negative, we take the negative to get positive MSE
mse_scores = -mse_scores

print(mse_scores)


# Get the average MSE score
average_mse = mse_scores.mean()

print(f"Average Cross-Validated MSE: {average_mse}")











example_data = pd.DataFrame({
    "color": ["red", "orange", "yellow", "green", "blue", "indigo", "violet"]
})
example_data





def kfolds(data, k):
    folds = []
    n = len(data)
    fold_sizes = [n // k + 1 if i < n % k else n // k for i in range(k)]
    
    start = 0
    for size in fold_sizes:
        end = start + size
        folds.append(data.iloc[start:end])
        start = end
    
    return folds


results = kfolds(example_data, 3)
for result in results:
    print(result, "\n")





# Apply kfolds() to ames_data with 5 folds
X_folds = kfolds(X, 5)
y_folds = kfolds(y, 5)





# Replace None with appropriate code
test_errs = []
k = 5

for n in range(k):
    # Split into train and test for the fold
    X_train = pd.concat([X_folds[i] for i in range(k) if i != n])
    X_test = X_folds[n]
    y_train = pd.concat([y_folds[i] for i in range(k) if i != n])
    y_test = y_folds[n]
    
    # Fit a linear regression model
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # Evaluate test errors
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    test_errs.append(mse)

print(test_errs)





# Compare your results with sklearn results
from sklearn.model_selection import cross_val_score

cross_val_mse = -cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')
print(cross_val_mse)

print("Manual CV Avg MSE:", np.mean(test_errs))
print("sklearn CV Avg MSE:", np.mean(cross_val_mse))









